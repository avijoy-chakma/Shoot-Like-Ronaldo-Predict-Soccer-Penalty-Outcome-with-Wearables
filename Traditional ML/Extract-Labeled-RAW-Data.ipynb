{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the Processed (IMU+Mag+Index of each segment of 128 Hz) IMU Data File\n",
    "# Access the Shot Segment Information\n",
    "# Extract the Labeled Short Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use annotation file to extract the active data points\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_url = os.getcwd()\n",
    "elan_url = os.path.abspath(os.path.join(home_url, '..', 'ELAN File'))\n",
    "segment_info_url = os.path.abspath(os.path.join(home_url, '..', 'Segment Information'))\n",
    "extracted_data_url = os.path.abspath(os.path.join(home_url, '..', 'Extracted Data Files'))\n",
    "\n",
    "P1_file = \"P1.csv\"\n",
    "P2_file = \"P2-P3.csv\"\n",
    "P3_file = \"P2-P3.csv\"\n",
    "P4_file = \"P4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/avijoy/Downloads/Penalty Shoot-out Github/Segment Information'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_info_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_df = pd.read_csv(elan_url + \"/\" + P1_file)\n",
    "P2_df = pd.read_csv(elan_url + \"/\" + P2_file)\n",
    "P3_df = pd.read_csv(elan_url + \"/\" + P3_file)\n",
    "P4_df = pd.read_csv(elan_url + \"/\" + P4_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot Segment Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_annotation = \"P1.txt\"\n",
    "P2_annotation = \"P2.txt\"\n",
    "P3_annotation = \"P3.txt\"\n",
    "P4_annotation = \"P4.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Timestamp',\n",
       " 'Accelerometer X',\n",
       " 'Accelerometer Y',\n",
       " 'Accelerometer Z',\n",
       " 'value',\n",
       " 'New Index']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(P1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace the Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_df.rename(columns={'Unnamed: 0': 'Index', 'Accelerometer X': 'X', 'Accelerometer Y': 'Y', 'Accelerometer Z': 'Z'}, inplace=True)\n",
    "P2_df.rename(columns={'Unnamed: 0': 'Index', 'Accelerometer X': 'X', 'Accelerometer Y': 'Y', 'Accelerometer Z': 'Z'}, inplace=True)\n",
    "P3_df.rename(columns={'Unnamed: 0': 'Index', 'Accelerometer X': 'X', 'Accelerometer Y': 'Y', 'Accelerometer Z': 'Z'}, inplace=True)\n",
    "P4_df.rename(columns={'Unnamed: 0': 'Index', 'Accelerometer X': 'X', 'Accelerometer Y': 'Y', 'Accelerometer Z': 'Z'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Redundant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_df.drop(['Timestamp', 'value', 'New Index'], axis=1, inplace=True)\n",
    "P2_df.drop(['Timestamp', 'value', 'New Index'], axis=1, inplace=True)\n",
    "P3_df.drop(['Timestamp', 'value', 'New Index'], axis=1, inplace=True)\n",
    "P4_df.drop(['Timestamp', 'value', 'New Index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Annotation and Create Separate Dataframe File\n",
    "    - Tokenize each shot(data) entry\n",
    "    - Aggregate different shots in different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file\n",
    "def read_annotation_file(df, file_name, user):\n",
    "    lg_df = pd.DataFrame(columns=['X','Y','Z'])\n",
    "    lt_df = pd.DataFrame(columns=['X','Y','Z'])\n",
    "    rg_df = pd.DataFrame(columns=['X','Y','Z'])\n",
    "    rt_df = pd.DataFrame(columns=['X','Y','Z'])\n",
    "    mg_df = pd.DataFrame(columns=['X','Y','Z'])\n",
    "    mt_df = pd.DataFrame(columns=['X','Y','Z'])\n",
    "\n",
    "    annotation_file = open(file_name)\n",
    "    for line in annotation_file:\n",
    "#         print(line)\n",
    "        tokens = line.split()\n",
    "        start = int(tokens[4])+1\n",
    "        end = int(tokens[7])+1\n",
    "        \n",
    "        item_df = df[start:end]\n",
    "        if (tokens[0] == 'LG'):\n",
    "            lg_df = pd.concat([lg_df,item_df], sort=True, axis = 0)\n",
    "        elif (tokens[0] == 'LT'):\n",
    "            lt_df = pd.concat([lt_df,item_df], sort=True, axis = 0)\n",
    "        elif (tokens[0] == 'RG'):\n",
    "            rg_df = pd.concat([rg_df,item_df], sort=True, axis = 0)\n",
    "        elif (tokens[0] == 'RT'):\n",
    "            rt_df = pd.concat([rt_df,item_df], sort=True, axis = 0)\n",
    "        elif (tokens[0] == 'MG'):\n",
    "            mg_df = pd.concat([mg_df,item_df], sort=True, axis = 0)\n",
    "        elif (tokens[0] == 'MT'):\n",
    "            mt_df = pd.concat([mt_df,item_df], sort=True, axis = 0)\n",
    "    annotation_file.close()\n",
    "    \n",
    "    lg_df['Label'] = 0\n",
    "    lt_df['Label'] = 1\n",
    "    rg_df['Label'] = 2\n",
    "    rt_df['Label'] = 3\n",
    "    mg_df['Label'] = 4\n",
    "    mt_df['Label'] = 5\n",
    "    \n",
    "    final_df = pd.concat([lg_df, lt_df, rg_df, rt_df, mg_df, mt_df], sort=True, axis = 0)\n",
    "    final_df['User'] = user\n",
    "    final_df.to_csv(extracted_data_url+ \"/\" + str(user)+'_raw_labeled.csv', float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_annotation_file(P1_df, segment_info_url + \"/\" + P1_annotation, \"P1\")\n",
    "read_annotation_file(P2_df, segment_info_url + \"/\" + P2_annotation, \"P2\")\n",
    "read_annotation_file(P3_df, segment_info_url + \"/\" + P3_annotation, \"P3\")\n",
    "read_annotation_file(P4_df, segment_info_url + \"/\" + P4_annotation, \"P4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
